{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# –ü–µ—Ä–µ–≤–æ–¥ –∫–∞–∂–¥–æ–π —Ç–∞–±–ª–∏—Ü—ã –≤ Parquet —Ñ–∞–π–ª\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables:\n\u001b[1;32m     17\u001b[0m   \u001b[38;5;66;03m# –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ç–∞–±–ª–∏—Ü—ã\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m   df \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39mTable\u001b[38;5;241m.\u001b[39mfrom_pandas(pd\u001b[38;5;241m.\u001b[39mread_sql_query(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, conn))\n\u001b[1;32m     20\u001b[0m   \u001b[38;5;66;03m# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ Parquet —Ñ–∞–π–ª\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#   pq.write_table(df, f\"{table}.parquet\")\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# pq.write_table(df, f\"{table}.csv\")\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# –ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è\u001b[39;00m\n\u001b[1;32m     25\u001b[0m conn\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:526\u001b[0m, in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[0;32m--> 526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[1;32m    527\u001b[0m         sql,\n\u001b[1;32m    528\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[1;32m    529\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    530\u001b[0m         coerce_float\u001b[38;5;241m=\u001b[39mcoerce_float,\n\u001b[1;32m    531\u001b[0m         parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[1;32m    532\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    533\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    534\u001b[0m         dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    535\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:2753\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2742\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query_iterator(\n\u001b[1;32m   2743\u001b[0m         cursor,\n\u001b[1;32m   2744\u001b[0m         chunksize,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2750\u001b[0m         dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   2751\u001b[0m     )\n\u001b[1;32m   2752\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2753\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetchall_as_list(cursor)\n\u001b[1;32m   2754\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m   2756\u001b[0m     frame \u001b[38;5;241m=\u001b[39m _wrap_result(\n\u001b[1;32m   2757\u001b[0m         data,\n\u001b[1;32m   2758\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2763\u001b[0m         dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   2764\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:2768\u001b[0m, in \u001b[0;36mSQLiteDatabase._fetchall_as_list\u001b[0;34m(self, cur)\u001b[0m\n\u001b[1;32m   2767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fetchall_as_list\u001b[39m(\u001b[38;5;28mself\u001b[39m, cur):\n\u001b[0;32m-> 2768\u001b[0m     result \u001b[38;5;241m=\u001b[39m cur\u001b[38;5;241m.\u001b[39mfetchall()\n\u001b[1;32m   2769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m   2770\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(result)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "\n",
    "# –ü—É—Ç—å –∫ SQLite —Ñ–∞–π–ª—É\n",
    "sqlite_file = 'db.sqlite'\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å SQLite –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "\n",
    "# –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ç–∞–±–ª–∏—Ü\n",
    "tables = [row[0] for row in conn.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")]\n",
    "\n",
    "# –ü–µ—Ä–µ–≤–æ–¥ –∫–∞–∂–¥–æ–π —Ç–∞–±–ª–∏—Ü—ã –≤ Parquet —Ñ–∞–π–ª\n",
    "for table in tables:\n",
    "  # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ç–∞–±–ª–∏—Ü—ã\n",
    "  df = pa.Table.from_pandas(pd.read_sql_query(f\"SELECT * FROM {table}\", conn))\n",
    "  \n",
    "  # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ Parquet —Ñ–∞–π–ª\n",
    "#   pq.write_table(df, f\"{table}.parquet\")\n",
    "# pq.write_table(df, f\"{table}.csv\")\n",
    "\n",
    "# –ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'user_id', 'first_name', 'last_name', 'city', 'education',\n",
      "       'work'],\n",
      "      dtype='object')\n",
      "Column: id\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 4573695 entries, 0 to 4573694\n",
      "Series name: id\n",
      "Non-Null Count    Dtype\n",
      "--------------    -----\n",
      "4573695 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 34.9 MB\n",
      "None\n",
      "Column: user_id\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 4573695 entries, 0 to 4573694\n",
      "Series name: user_id\n",
      "Non-Null Count    Dtype\n",
      "--------------    -----\n",
      "4573695 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 34.9 MB\n",
      "None\n",
      "Column: first_name\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 4573695 entries, 0 to 4573694\n",
      "Series name: first_name\n",
      "Non-Null Count    Dtype \n",
      "--------------    ----- \n",
      "4573695 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 34.9+ MB\n",
      "None\n",
      "Column: last_name\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 4573695 entries, 0 to 4573694\n",
      "Series name: last_name\n",
      "Non-Null Count    Dtype \n",
      "--------------    ----- \n",
      "4536968 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 34.9+ MB\n",
      "None\n",
      "Column: city\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 4573695 entries, 0 to 4573694\n",
      "Series name: city\n",
      "Non-Null Count    Dtype \n",
      "--------------    ----- \n",
      "2657969 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 34.9+ MB\n",
      "None\n",
      "Column: education\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 4573695 entries, 0 to 4573694\n",
      "Series name: education\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "0 non-null      object\n",
      "dtypes: object(1)\n",
      "memory usage: 34.9+ MB\n",
      "None\n",
      "Column: work\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 4573695 entries, 0 to 4573694\n",
      "Series name: work\n",
      "Non-Null Count   Dtype \n",
      "--------------   ----- \n",
      "168903 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 34.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ parquet —Ñ–∞–π–ª–∞\n",
    "df_friend = pd.read_parquet(\"friend.parquet\")\n",
    "print(df_friend.columns)\n",
    "\n",
    "# –í—ã–≤–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏—è –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–∞–∂–¥–æ–º —Å—Ç–æ–ª–±—Ü–µ\n",
    "for i in df_friend.columns:\n",
    "    print(f\"Column: {i}\")\n",
    "    print(df_friend[f'{i}'].info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'user_id', 'activity', 'interests', 'music', 'films', 'tv',\n",
      "       'books', 'games', 'quotes', 'about'],\n",
      "      dtype='object')\n",
      "Column: id\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 27239 entries, 0 to 27238\n",
      "Series name: id\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "27239 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 212.9 KB\n",
      "None\n",
      "Column: user_id\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 27239 entries, 0 to 27238\n",
      "Series name: user_id\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "27239 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 212.9 KB\n",
      "None\n",
      "Column: activity\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 27239 entries, 0 to 27238\n",
      "Series name: activity\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "733 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 212.9+ KB\n",
      "None\n",
      "Column: interests\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 27239 entries, 0 to 27238\n",
      "Series name: interests\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "834 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 212.9+ KB\n",
      "None\n",
      "Column: music\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 27239 entries, 0 to 27238\n",
      "Series name: music\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "816 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 212.9+ KB\n",
      "None\n",
      "Column: films\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 27239 entries, 0 to 27238\n",
      "Series name: films\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "683 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 212.9+ KB\n",
      "None\n",
      "Column: tv\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 27239 entries, 0 to 27238\n",
      "Series name: tv\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "441 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 212.9+ KB\n",
      "None\n",
      "Column: books\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 27239 entries, 0 to 27238\n",
      "Series name: books\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "589 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 212.9+ KB\n",
      "None\n",
      "Column: games\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 27239 entries, 0 to 27238\n",
      "Series name: games\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "635 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 212.9+ KB\n",
      "None\n",
      "Column: quotes\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 27239 entries, 0 to 27238\n",
      "Series name: quotes\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "711 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 212.9+ KB\n",
      "None\n",
      "Column: about\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 27239 entries, 0 to 27238\n",
      "Series name: about\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "886 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 212.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>activity</th>\n",
       "      <th>interests</th>\n",
       "      <th>music</th>\n",
       "      <th>films</th>\n",
       "      <th>tv</th>\n",
       "      <th>books</th>\n",
       "      <th>games</th>\n",
       "      <th>quotes</th>\n",
       "      <th>about</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  user_id activity interests music films    tv books games quotes about\n",
       "0   1        1     None      None  None  None  None  None  None   None  None\n",
       "1   2        2     None      None  None  None  None  None  None   None  None\n",
       "2   3        3     None      None  None  None  None  None  None   None  None\n",
       "3   4        4     None      None  None  None  None  None  None   None  None\n",
       "4   5        5     None      None  None  None  None  None  None   None  None"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_biography = pd.read_parquet(\"biography.parquet\")\n",
    "print(df_biography.columns)\n",
    "# –í—ã–≤–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏—è –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–∞–∂–¥–æ–º —Å—Ç–æ–ª–±—Ü–µ\n",
    "for i in df_biography.columns:\n",
    "    print(f\"Column: {i}\")\n",
    "    print(df_biography[f'{i}'].info())\n",
    "    \n",
    "df_biography.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'user_id', 'name', 'description'], dtype='object')\n",
      "Column: id\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 1829882 entries, 0 to 1829881\n",
      "Series name: id\n",
      "Non-Null Count    Dtype\n",
      "--------------    -----\n",
      "1829882 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 14.0 MB\n",
      "None\n",
      "Column: user_id\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 1829882 entries, 0 to 1829881\n",
      "Series name: user_id\n",
      "Non-Null Count    Dtype\n",
      "--------------    -----\n",
      "1829882 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 14.0 MB\n",
      "None\n",
      "Column: name\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 1829882 entries, 0 to 1829881\n",
      "Series name: name\n",
      "Non-Null Count    Dtype \n",
      "--------------    ----- \n",
      "1829882 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 14.0+ MB\n",
      "None\n",
      "Column: description\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 1829882 entries, 0 to 1829881\n",
      "Series name: description\n",
      "Non-Null Count    Dtype \n",
      "--------------    ----- \n",
      "1516942 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 14.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_group_table = pd.read_parquet(\"group_table.parquet\")\n",
    "print(df_group_table.columns)\n",
    "\n",
    "for i in df_group_table.columns:\n",
    "    print(f\"Column: {i}\")\n",
    "    print(df_group_table[f'{i}'].info())\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "—Ä–∞–±–æ—Ç–∞ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º, –≤—ã—Ç–∞—Å–∫–∏–≤–∞—é —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç—å –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1829882, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "description\n",
       "False    1516942\n",
       "True      312940\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_group_table.sample(5)\n",
    "print(df_group_table.shape)\n",
    "df_group_table['description'].isna().value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def count_caps_words(text):\n",
    "    if isinstance(text, str):\n",
    "        caps_words = re.findall(r'\\b[A-Z–ê-–Ø–Å]{2,}\\b', text)\n",
    "        return len(caps_words)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∫ –∫–æ–ª–æ–Ω–∫–µ 'text'\n",
    "df_group_table['caps_words_count_desc'] = df_group_table['description'].apply(count_caps_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_table['word_count_desc'] = df_group_table['description'].apply(lambda x: len(x.split()) if isinstance(x, str) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Downloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m640.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: emoji\n",
      "Successfully installed emoji-2.14.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     17\u001b[0m df_group_table[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoded_desc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_group_table[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(decode_html_entities)\n\u001b[0;32m---> 18\u001b[0m df_group_table[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memoji_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_group_table[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoded_desc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(count_emojis)\n\u001b[1;32m     19\u001b[0m df_group_table\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoded_desc\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m, in \u001b[0;36mcount_emojis\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount_emojis\u001b[39m(text):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(emoji\u001b[38;5;241m.\u001b[39memoji_list(text))\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/emoji/core.py:367\u001b[0m, in \u001b[0;36memoji_list\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21memoji_list\u001b[39m(string: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[_EmojiListReturn]:\n\u001b[1;32m    360\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Returns the location and emoji in list of dict format.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m        >>> emoji.emoji_list(\"Hi, I am fine. üòÅ\")\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m        [{'match_start': 15, 'match_end': 16, 'emoji': 'üòÅ'}]\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 367\u001b[0m         {\n\u001b[1;32m    368\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch_start\u001b[39m\u001b[38;5;124m'\u001b[39m: m\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mstart,\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch_end\u001b[39m\u001b[38;5;124m'\u001b[39m: m\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mend,\n\u001b[1;32m    370\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124memoji\u001b[39m\u001b[38;5;124m'\u001b[39m: m\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39memoji,\n\u001b[1;32m    371\u001b[0m         }\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m tokenize(string, keep_zwj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m\u001b[38;5;241m.\u001b[39mvalue, EmojiMatch)\n\u001b[1;32m    374\u001b[0m     ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "import html\n",
    "\n",
    "\n",
    "def decode_html_entities(text):\n",
    "    if isinstance(text, str):\n",
    "        return html.unescape(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def count_emojis(text):\n",
    "    if isinstance(text, str):\n",
    "        return len(emoji.emoji_list(text))\n",
    "    return 0\n",
    "\n",
    "\n",
    "df_group_table['decoded_desc'] = df_group_table['description'].apply(decode_html_entities)\n",
    "df_group_table['emoji_count'] = df_group_table['decoded_desc'].apply(count_emojis)\n",
    "df_group_table.drop(\"decoded_desc\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>word_count_desc</th>\n",
       "      <th>caps_words_count_desc</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>url_count_desc</th>\n",
       "      <th>hashtag_count_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>559576</th>\n",
       "      <td>559609</td>\n",
       "      <td>19576</td>\n",
       "      <td>–®–∫–æ–ª–∞ –∫—Ä–∞—Å–æ—Ç—ã</td>\n",
       "      <td>‚ú®–õ—É—á—à–∏–µ –∏–¥–µ–∏ –º–∞–∫–∏—è–∂–∞ üëÑ, –º–∞–Ω–∏–∫—é—Ä–∞ üíÖ –∏ –ø—Ä–∏—á–µ—Å–æ–∫ ...</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926824</th>\n",
       "      <td>928576</td>\n",
       "      <td>50747</td>\n",
       "      <td>–ü–æ—Ä–µ–±—Ä–∏–∫ –ü–∏—Ç–µ—Ä</td>\n",
       "      <td>üëçüèª–¢—ã –Ω–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ü–û–†–ï–ë–†–ò–ö! –ü–æ–¥–ø–∏—à–∏—Å—å!\\...</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124871</th>\n",
       "      <td>124879</td>\n",
       "      <td>1677</td>\n",
       "      <td>–ê–≤—Ç–æ—Ä—ã–Ω–æ–∫  –î–ù–† / –õ–ù–† –î–æ–Ω–µ—Ü–∫ –õ—É–≥–∞–Ω—Å–∫</td>\n",
       "      <td>–ê–≤—Ç–æ—Ä—ã–Ω–æ–∫  –≤ –î–ù–† / –õ–ù–† –î–æ–Ω–µ—Ü–∫ –õ—É–≥–∞–Ω—Å–∫ - –±–æ–ª—å—à–æ...</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508516</th>\n",
       "      <td>2093286</td>\n",
       "      <td>95723</td>\n",
       "      <td>–¢ –æ –Ω</td>\n",
       "      <td>—Å–æ–æ–±—â–µ—Å—Ç–≤–æ –ü—Å–∏—Ö–æ–ª–æ–≥–∏–∏, –ñ–∏–∑–Ω–∏ –∏ –¢–æ–Ω–∫–æ–≥–æ —é–º–æ—Ä–∞</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305545</th>\n",
       "      <td>1348911</td>\n",
       "      <td>70030</td>\n",
       "      <td>–•–æ—á—É –ø—Ä–∏–∑–Ω–∞—Ç—å—Å—è</td>\n",
       "      <td>–í—Å–µ –≤–∞—à–∏ –ø–æ—Å—Ç—ã —Ä–∞–∑–º–µ—â–∞—é—Ç—Å—è –ê–Ω–æ–Ω–∏–º–Ω–æ.\\n\\n¬´–•–æ—á—É ...</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  user_id                                 name  \\\n",
       "559576    559609    19576                        –®–∫–æ–ª–∞ –∫—Ä–∞—Å–æ—Ç—ã   \n",
       "926824    928576    50747                       –ü–æ—Ä–µ–±—Ä–∏–∫ –ü–∏—Ç–µ—Ä   \n",
       "124871    124879     1677  –ê–≤—Ç–æ—Ä—ã–Ω–æ–∫  –î–ù–† / –õ–ù–† –î–æ–Ω–µ—Ü–∫ –õ—É–≥–∞–Ω—Å–∫   \n",
       "1508516  2093286    95723                                –¢ –æ –Ω   \n",
       "1305545  1348911    70030                      –•–æ—á—É –ø—Ä–∏–∑–Ω–∞—Ç—å—Å—è   \n",
       "\n",
       "                                               description  word_count_desc  \\\n",
       "559576   ‚ú®–õ—É—á—à–∏–µ –∏–¥–µ–∏ –º–∞–∫–∏—è–∂–∞ üëÑ, –º–∞–Ω–∏–∫—é—Ä–∞ üíÖ –∏ –ø—Ä–∏—á–µ—Å–æ–∫ ...               27   \n",
       "926824   üëçüèª–¢—ã –Ω–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ü–û–†–ï–ë–†–ò–ö! –ü–æ–¥–ø–∏—à–∏—Å—å!\\...               28   \n",
       "124871   –ê–≤—Ç–æ—Ä—ã–Ω–æ–∫  –≤ –î–ù–† / –õ–ù–† –î–æ–Ω–µ—Ü–∫ –õ—É–≥–∞–Ω—Å–∫ - –±–æ–ª—å—à–æ...               26   \n",
       "1508516       —Å–æ–æ–±—â–µ—Å—Ç–≤–æ –ü—Å–∏—Ö–æ–ª–æ–≥–∏–∏, –ñ–∏–∑–Ω–∏ –∏ –¢–æ–Ω–∫–æ–≥–æ —é–º–æ—Ä–∞                6   \n",
       "1305545  –í—Å–µ –≤–∞—à–∏ –ø–æ—Å—Ç—ã —Ä–∞–∑–º–µ—â–∞—é—Ç—Å—è –ê–Ω–æ–Ω–∏–º–Ω–æ.\\n\\n¬´–•–æ—á—É ...               24   \n",
       "\n",
       "         caps_words_count_desc  emoji_count  url_count_desc  \\\n",
       "559576                       0           14               0   \n",
       "926824                       1            3               0   \n",
       "124871                       2            0               0   \n",
       "1508516                      0            0               0   \n",
       "1305545                      1            0               0   \n",
       "\n",
       "         hashtag_count_desc  \n",
       "559576                    0  \n",
       "926824                    0  \n",
       "124871                    0  \n",
       "1508516                   0  \n",
       "1305545                   0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_group_table.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_urls(text):\n",
    "    if isinstance(text, str):\n",
    "        return len(re.findall(r'http[s]?://\\S+', text))\n",
    "    return 0\n",
    "\n",
    "\n",
    "df_group_table['url_count_desc'] = df_group_table['description'].apply(count_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_hashtags(text):\n",
    "    if isinstance(text, str):\n",
    "        return len(re.findall(r'#\\w+', text))\n",
    "    return 0\n",
    "\n",
    "\n",
    "df_group_table['hashtag_count_desc'] = df_group_table['description'].apply(count_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_mentions(text):\n",
    "    if isinstance(text, str):\n",
    "        return len(re.findall(r'@\\w+', text))\n",
    "    return 0\n",
    "\n",
    "\n",
    "df_group_table['mention_count_desc'] = df_group_table['description'].apply(count_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/dar.ai/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dar.ai/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words_ru = set(stopwords.words('russian'))\n",
    "stop_words_en = set(stopwords.words('english'))\n",
    "combined_stop_words = stop_words_ru.union(stop_words_en)\n",
    "\n",
    "\n",
    "def count_stopwords(text):\n",
    "    if isinstance(text, str):\n",
    "        words = word_tokenize(text.lower(), language='russian')\n",
    "        return sum(1 for word in words if word in combined_stop_words)\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "df_group_table['stopwords_count_desc'] = df_group_table['description'].apply(count_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(words))\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 8\u001b[0m df_group_table[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_words_count_desc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_group_table[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(count_unique_words)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m, in \u001b[0;36mcount_unique_words\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount_unique_words\u001b[39m(text):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m         words \u001b[38;5;241m=\u001b[39m word_tokenize(text\u001b[38;5;241m.\u001b[39mlower())\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(words))\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "def count_unique_words(text):\n",
    "    if isinstance(text, str):\n",
    "        words = word_tokenize(text.lower())\n",
    "        return len(set(words))\n",
    "    return 0\n",
    "\n",
    "\n",
    "df_group_table['unique_words_count_desc'] = df_group_table['description'].apply(count_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_questions(text):\n",
    "    if isinstance(text, str):\n",
    "        return len(re.findall(r'\\?', text))\n",
    "    return 0\n",
    "\n",
    "\n",
    "df_group_table['question_count_desc'] = df_group_table['description'].apply(count_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caps_ratio(text):\n",
    "    if isinstance(text, str):\n",
    "        caps = sum(1 for char in text if char.isupper())\n",
    "        total = len(text)\n",
    "        return caps / total if total > 0 else 0\n",
    "    return 0\n",
    "\n",
    "\n",
    "df_group_table['caps_ratio_sec'] = df_group_table['description'].apply(caps_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_numbers(text):\n",
    "    if isinstance(text, str):\n",
    "        return len(re.findall(r'\\b\\d+\\b', text))\n",
    "    return 0\n",
    "\n",
    "\n",
    "df_group_table['number_count_desc'] = df_group_table['description'].apply(count_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>caps_words_count_desc</th>\n",
       "      <th>word_count_desc</th>\n",
       "      <th>decoded_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W Œõ R</td>\n",
       "      <td>#WAR_music - –º—É–∑—ã–∫–∞\\n#WAR_look - –ª—É–∫–∏\\n#WAR_gi...</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>#WAR_music - –º—É–∑—ã–∫–∞\\n#WAR_look - –ª—É–∫–∏\\n#WAR_gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>–ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –¢–∞–∏–ª–∞–Ω–¥ /interesting Thailand</td>\n",
       "      <td>–ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –¢–∞–∏–ª–∞–Ω–¥ - –≤—Å–µ –æ –¢–∞–∏–ª–∞–Ω–¥–µ, –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>–ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –¢–∞–∏–ª–∞–Ω–¥ - –≤—Å–µ –æ –¢–∞–∏–ª–∞–Ω–¥–µ, –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Asian Girls –°ollection</td>\n",
       "      <td>–ü–æ–¥–±–æ—Ä–∫–∏ —Ñ–æ—Ç–æ</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>–ü–æ–¥–±–æ—Ä–∫–∏ —Ñ–æ—Ç–æ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>–ì–∞–ª–∏–ª–µ–æ | –ß—É–¥–æ –ò–Ω–∂–µ–Ω–µ—Ä–∏–∏</td>\n",
       "      <td>–ù–∞—É–∫–∞, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, –∏–Ω–∂–µ–Ω–µ—Ä–Ω–æ–µ –¥–µ–ª–æ, —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω...</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>–ù–∞—É–∫–∞, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, –∏–Ω–∂–µ–Ω–µ—Ä–Ω–æ–µ –¥–µ–ª–æ, —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Sexy Nurse</td>\n",
       "      <td>http://xxtube98.com/\\n\\nif u want to more funn...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>http://xxtube98.com/\\n\\nif u want to more funn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  user_id                                      name  \\\n",
       "0   1        2                                     W Œõ R   \n",
       "1   2        2  –ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –¢–∞–∏–ª–∞–Ω–¥ /interesting Thailand   \n",
       "2   3        2                    Asian Girls –°ollection   \n",
       "3   4        2                  –ì–∞–ª–∏–ª–µ–æ | –ß—É–¥–æ –ò–Ω–∂–µ–Ω–µ—Ä–∏–∏   \n",
       "4   5        2                                Sexy Nurse   \n",
       "\n",
       "                                         description  caps_words_count_desc  \\\n",
       "0  #WAR_music - –º—É–∑—ã–∫–∞\\n#WAR_look - –ª—É–∫–∏\\n#WAR_gi...                      0   \n",
       "1  –ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –¢–∞–∏–ª–∞–Ω–¥ - –≤—Å–µ –æ –¢–∞–∏–ª–∞–Ω–¥–µ, –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã...                      0   \n",
       "2                                      –ü–æ–¥–±–æ—Ä–∫–∏ —Ñ–æ—Ç–æ                      0   \n",
       "3  –ù–∞—É–∫–∞, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, –∏–Ω–∂–µ–Ω–µ—Ä–Ω–æ–µ –¥–µ–ª–æ, —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω...                      1   \n",
       "4  http://xxtube98.com/\\n\\nif u want to more funn...                      0   \n",
       "\n",
       "   word_count_desc                                       decoded_desc  \n",
       "0               28  #WAR_music - –º—É–∑—ã–∫–∞\\n#WAR_look - –ª—É–∫–∏\\n#WAR_gi...  \n",
       "1                9  –ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –¢–∞–∏–ª–∞–Ω–¥ - –≤—Å–µ –æ –¢–∞–∏–ª–∞–Ω–¥–µ, –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã...  \n",
       "2                2                                      –ü–æ–¥–±–æ—Ä–∫–∏ —Ñ–æ—Ç–æ  \n",
       "3               46  –ù–∞—É–∫–∞, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, –∏–Ω–∂–µ–Ω–µ—Ä–Ω–æ–µ –¥–µ–ª–æ, —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω...  \n",
       "4                9  http://xxtube98.com/\\n\\nif u want to more funn...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_group_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'user_id', 'igm2txt', 'url', 'like_count'], dtype='object')\n",
      "Column: id\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 211881 entries, 0 to 211880\n",
      "Series name: id\n",
      "Non-Null Count   Dtype\n",
      "--------------   -----\n",
      "211881 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 1.6 MB\n",
      "None\n",
      "Column: user_id\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 211881 entries, 0 to 211880\n",
      "Series name: user_id\n",
      "Non-Null Count   Dtype\n",
      "--------------   -----\n",
      "211881 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 1.6 MB\n",
      "None\n",
      "Column: igm2txt\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 211881 entries, 0 to 211880\n",
      "Series name: igm2txt\n",
      "Non-Null Count   Dtype \n",
      "--------------   ----- \n",
      "211881 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.6+ MB\n",
      "None\n",
      "Column: url\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 211881 entries, 0 to 211880\n",
      "Series name: url\n",
      "Non-Null Count   Dtype \n",
      "--------------   ----- \n",
      "211881 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.6+ MB\n",
      "None\n",
      "Column: like_count\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 211881 entries, 0 to 211880\n",
      "Series name: like_count\n",
      "Non-Null Count   Dtype\n",
      "--------------   -----\n",
      "211881 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 1.6 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>igm2txt</th>\n",
       "      <th>url</th>\n",
       "      <th>like_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>a photography of a person in a protective suit...</td>\n",
       "      <td>https://sun9-44.userapi.com/s/v1/ig2/oORXcNP6D...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a photography of a nurse wearing a mask</td>\n",
       "      <td>https://sun9-71.userapi.com/s/v1/ig2/evUGoA8RF...</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>a photography of a person ' s hand holding a c...</td>\n",
       "      <td>https://sun9-41.userapi.com/s/v1/ig2/JWFmarLza...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a photography of a person ' s butt with the wo...</td>\n",
       "      <td>https://sun9-24.userapi.com/s/v1/ig2/uWFCQMp8n...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>a photography of a doctor examining a patient ...</td>\n",
       "      <td>https://sun9-66.userapi.com/s/v1/ig2/P3h58YKeH...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  user_id                                            igm2txt  \\\n",
       "0   1        2  a photography of a person in a protective suit...   \n",
       "1   2        2            a photography of a nurse wearing a mask   \n",
       "2   3        2  a photography of a person ' s hand holding a c...   \n",
       "3   4        2  a photography of a person ' s butt with the wo...   \n",
       "4   5        2  a photography of a doctor examining a patient ...   \n",
       "\n",
       "                                                 url  like_count  \n",
       "0  https://sun9-44.userapi.com/s/v1/ig2/oORXcNP6D...          18  \n",
       "1  https://sun9-71.userapi.com/s/v1/ig2/evUGoA8RF...         152  \n",
       "2  https://sun9-41.userapi.com/s/v1/ig2/JWFmarLza...          14  \n",
       "3  https://sun9-24.userapi.com/s/v1/ig2/uWFCQMp8n...          25  \n",
       "4  https://sun9-66.userapi.com/s/v1/ig2/P3h58YKeH...          27  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_photo = pd.read_parquet(\"photo.parquet\")\n",
    "print(df_photo.columns)\n",
    "\n",
    "for i in df_photo.columns:\n",
    "    print(f\"Column: {i}\")\n",
    "    print(df_photo[f'{i}'].info())\n",
    "    \n",
    "\n",
    "df_photo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.45.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.6.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.45.2)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.12/site-packages (3.0.1)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers datasets torch scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df82b5fd3644e4cad7367e0756ad923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/380 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c806a4081345c5be3a6c4ff7c143a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd17a89602e4a1fab2b4e912d1ac337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204fa065d20d459fa6fc784452b99bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02770064dd714bc29aff039f381eba04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76ee1641bb64257b5d05e24e4723acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  27%|##7       | 136M/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∏ –º–æ–¥–µ–ª—å\n",
    "model_name = \"SamLowe/roberta-base-go_emotions\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "categories = [\n",
    "    \"Selfies\", \"Behind the Scenes\", \"Motivation\", \"Fitness Progress\", \"Food and Recipes\",\n",
    "    \"Outfits of the Day (OOTD)\", \"Travel Adventures\", \"Workout Routines\", \"Morning Routine\",\n",
    "    \"Before and After\", \"Inspirational Quotes\", \"Pets and Animals\", \"Friends and Hangouts\",\n",
    "    \"Product Reviews\", \"Unboxing\", \"Memes\", \"Challenges\", \"Tutorials\", \"Sneak Peeks\", \"Giveaways\",\n",
    "    \"Shoutouts\", \"Parties and Events\", \"Concerts and Live Performances\", \"Shopping Hauls\",\n",
    "    \"Makeup and Beauty\", \"Behind the Camera\", \"Work in Progress\", \"Transformation Stories\",\n",
    "    \"Street Style\", \"Life Hacks\", \"Travel Tips\", \"Day in the Life\", \"Fitness Challenges\", \"Vlogs\",\n",
    "    \"Home Decor\", \"Tech Reviews\", \"Fan Art\", \"Pets Doing Tricks\", \"Relationship Goals\", \"Q&A Sessions\",\n",
    "    \"Polls and Quizzes\", \"Daily Inspiration\", \"Gratitude Posts\", \"Current Events\", \"Charity and Activism\",\n",
    "    \"Product Launch\", \"Flash Sales\", \"Collaborations\", \"Testimonials\", \"Seasonal Posts\", \"Throwback Thursday (#TBT)\"\n",
    "]\n",
    "\n",
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è zero-shot –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         a photography of a person in a protective suit...\n",
       "1                   a photography of a nurse wearing a mask\n",
       "2         a photography of a person  s hand holding a ca...\n",
       "3         a photography of a person  s butt with the wor...\n",
       "4         a photography of a doctor examining a patient ...\n",
       "                                ...                        \n",
       "211876    a photography of deadpool and deadpool in dead...\n",
       "211877    a photography of a troll troll troll troll tro...\n",
       "211878                a photography of deadpool in deadpool\n",
       "211879    a photography of a man in a hoodie walking dow...\n",
       "211880    a photography of baby yoo yo yo yo yo yo yo yo...\n",
       "Name: igm2txt, Length: 211881, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def normalize_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = re.sub(r'<br>', ' ', text)\n",
    "        #text = ''.join(char for char in text if char.isalnum() or char.isspace() or char in emoji.EMOJI_DATA.values())\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "        # –ó–∞–º–µ–Ω–∞ –Ω–µ—Ä—É—Å—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –ø—É—Å—Ç—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏\n",
    "        #text = ''.join([char if ord(char) < 128 else '' for char in text]) \n",
    "\n",
    "        return text\n",
    "    return ''\n",
    "\n",
    "\n",
    "df_photo['igm2txt'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (4.66.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/10 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m] \n\u001b[1;32m      5\u001b[0m df_photo_subset \u001b[38;5;241m=\u001b[39m df_photo\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      6\u001b[0m df_photo_subset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_category\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 7\u001b[0m     classify_text(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m tqdm(df_photo_subset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124migm2txt\u001b[39m\u001b[38;5;124m'\u001b[39m], desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m ]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_photo_subset[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124migm2txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_category\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m, in \u001b[0;36mclassify_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassify_text\u001b[39m(text):\n\u001b[0;32m----> 2\u001b[0m     result \u001b[38;5;241m=\u001b[39m classifier(text, candidate_labels\u001b[38;5;241m=\u001b[39mcategories)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/zero_shot_classification.py:206\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.__call__\u001b[0;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to understand extra arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(sequences, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/base.py:1260\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ChunkPipeline):\n\u001b[0;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1261\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1262\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   1263\u001b[0m                 [inputs], num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1264\u001b[0m             )\n\u001b[1;32m   1265\u001b[0m         )\n\u001b[1;32m   1266\u001b[0m     )\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:269\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[0;32m--> 269\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/base.py:1175\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1174\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1175\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[1;32m   1176\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/zero_shot_classification.py:229\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline._forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    228\u001b[0m     model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs)\n\u001b[1;32m    231\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandidate_label\u001b[39m\u001b[38;5;124m\"\u001b[39m: candidate_label,\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m\"\u001b[39m: sequence,\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_last\u001b[39m\u001b[38;5;124m\"\u001b[39m: inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_last\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moutputs,\n\u001b[1;32m    236\u001b[0m }\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_outputs\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:1802\u001b[0m, in \u001b[0;36mBartForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1799\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing input embeddings is currently not supported for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1800\u001b[0m     )\n\u001b[0;32m-> 1802\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m   1803\u001b[0m     input_ids,\n\u001b[1;32m   1804\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1805\u001b[0m     decoder_input_ids\u001b[38;5;241m=\u001b[39mdecoder_input_ids,\n\u001b[1;32m   1806\u001b[0m     decoder_attention_mask\u001b[38;5;241m=\u001b[39mdecoder_attention_mask,\n\u001b[1;32m   1807\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m   1808\u001b[0m     decoder_head_mask\u001b[38;5;241m=\u001b[39mdecoder_head_mask,\n\u001b[1;32m   1809\u001b[0m     cross_attn_head_mask\u001b[38;5;241m=\u001b[39mcross_attn_head_mask,\n\u001b[1;32m   1810\u001b[0m     encoder_outputs\u001b[38;5;241m=\u001b[39mencoder_outputs,\n\u001b[1;32m   1811\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1812\u001b[0m     decoder_inputs_embeds\u001b[38;5;241m=\u001b[39mdecoder_inputs_embeds,\n\u001b[1;32m   1813\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1814\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1815\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1816\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1817\u001b[0m )\n\u001b[1;32m   1818\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# last hidden state\u001b[39;00m\n\u001b[1;32m   1820\u001b[0m eos_mask \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39meq(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39meos_token_id)\u001b[38;5;241m.\u001b[39mto(hidden_states\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:1528\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1521\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1522\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1523\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1524\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1525\u001b[0m     )\n\u001b[1;32m   1527\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1528\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\n\u001b[1;32m   1529\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39mdecoder_input_ids,\n\u001b[1;32m   1530\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mdecoder_attention_mask,\n\u001b[1;32m   1531\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1532\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1533\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mdecoder_head_mask,\n\u001b[1;32m   1534\u001b[0m     cross_attn_head_mask\u001b[38;5;241m=\u001b[39mcross_attn_head_mask,\n\u001b[1;32m   1535\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1536\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39mdecoder_inputs_embeds,\n\u001b[1;32m   1537\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1538\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1539\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1540\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1541\u001b[0m )\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:1380\u001b[0m, in \u001b[0;36mBartDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1368\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1369\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1377\u001b[0m         use_cache,\n\u001b[1;32m   1378\u001b[0m     )\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1380\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[1;32m   1381\u001b[0m         hidden_states,\n\u001b[1;32m   1382\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1383\u001b[0m         encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[1;32m   1384\u001b[0m         encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[1;32m   1385\u001b[0m         layer_head_mask\u001b[38;5;241m=\u001b[39m(head_mask[idx] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1386\u001b[0m         cross_attn_layer_head_mask\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1387\u001b[0m             cross_attn_head_mask[idx] \u001b[38;5;28;01mif\u001b[39;00m cross_attn_head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1388\u001b[0m         ),\n\u001b[1;32m   1389\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mpast_key_value,\n\u001b[1;32m   1390\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1391\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1392\u001b[0m     )\n\u001b[1;32m   1393\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:702\u001b[0m, in \u001b[0;36mBartDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n\u001b[1;32m    701\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 702\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(hidden_states))\n\u001b[1;32m    703\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_dropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    704\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(hidden_states)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def classify_text(text):\n",
    "    result = classifier(text, candidate_labels=categories)\n",
    "    return result['labels'][0] \n",
    "\n",
    "df_photo_subset = df_photo.head(10)\n",
    "df_photo_subset['predicted_category'] = [\n",
    "    classify_text(text) for text in tqdm(df_photo_subset['igm2txt'], desc=\"Processing\")\n",
    "]\n",
    "print(df_photo_subset[['igm2txt', 'predicted_category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_photo['predicted_category'] = df_photo['img2txt'].apply(classify_text)\n",
    "\n",
    "# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "print(df_photo[['img2txt', 'predicted_category']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline, AutoTokenizer, AutoModelForSequenceClassification\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "# from datasets import load_dataset, Dataset\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–ø—Ä–∏–º–µ—Ä)\n",
    "# data = {\n",
    "#     \"text\": [\n",
    "#         \"A beautiful shot of a landscape with mountains\",  # –ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞\n",
    "#         \"An artistic black and white portrait\",  # –ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞\n",
    "#         # –î–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö\n",
    "#     ],\n",
    "#     \"labels\": [\n",
    "#         \"Landscape Photography\",  # –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è\n",
    "#         \"Black and White Photography\",  # –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è\n",
    "#         # –î–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ –º–µ—Ç–æ–∫ –¥–ª—è –ø—Ä–∏–º–µ—Ä–æ–≤\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç Dataset\n",
    "# df = Dataset.from_dict(data)\n",
    "\n",
    "# # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∏ –ª–µ–π–±–ª–∏–Ω–≥\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤ —á–∏—Å–ª–æ–≤—ã–µ –º–µ—Ç–∫–∏\n",
    "# label_encoder = LabelEncoder()\n",
    "# df = df.map(lambda examples: {'labels': label_encoder.fit_transform([examples['labels']])[0]})\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# tokenized_datasets = df.map(tokenize_function, batched=True)\n",
    "\n",
    "# # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏\n",
    "# train_test_data = tokenized_datasets.train_test_split(test_size=0.2)\n",
    "\n",
    "# # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å BERT –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "# model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(categories))\n",
    "\n",
    "# # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./results\",\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     learning_rate=2e-5,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     num_train_epochs=3,\n",
    "#     weight_decay=0.01,\n",
    "# )\n",
    "\n",
    "# # Trainer –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_test_data['train'],\n",
    "#     eval_dataset=train_test_data['test'],\n",
    "# )\n",
    "\n",
    "# # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "# trainer.train()\n",
    "\n",
    "# # –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ\n",
    "# trainer.evaluate()\n",
    "\n",
    "# # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "# def predict_category(text):\n",
    "#     inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\")\n",
    "#     outputs = model(**inputs)\n",
    "#     prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
    "#     category = label_encoder.inverse_transform([prediction])\n",
    "#     return category[0]\n",
    "\n",
    "# # –¢–µ—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
    "# text = \"A family portrait with bright smiles\"\n",
    "# predicted_category = predict_category(text)\n",
    "# print(f\"Predicted category: {predicted_category}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'user_id', 'text', 'isowner', 'date'], dtype='object')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_photo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m df_post \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_post\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m df_photo\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df_post[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39minfo())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_photo' is not defined"
     ]
    }
   ],
   "source": [
    "df_post = pd.read_parquet(\"post.parquet\")\n",
    "print(df_post.columns)\n",
    "\n",
    "for i in df_photo.columns:\n",
    "    print(f\"Column: {i}\")\n",
    "    print(df_post[f'{i}'].info())\n",
    "\n",
    "df_post.sample(15)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'vk_id', 'first_name', 'last_name', 'birth_date', 'age'], dtype='object')\n",
      "Column: id\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 27240 entries, 0 to 27239\n",
      "Series name: id\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "27240 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 212.9 KB\n",
      "None\n",
      "Column: vk_id\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 27240 entries, 0 to 27239\n",
      "Series name: vk_id\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "27240 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 212.9+ KB\n",
      "None\n",
      "Column: first_name\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 27240 entries, 0 to 27239\n",
      "Series name: first_name\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "27240 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 212.9+ KB\n",
      "None\n",
      "Column: last_name\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 27240 entries, 0 to 27239\n",
      "Series name: last_name\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "27240 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 212.9+ KB\n",
      "None\n",
      "Column: birth_date\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 27240 entries, 0 to 27239\n",
      "Series name: birth_date\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "27240 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 212.9+ KB\n",
      "None\n",
      "Column: age\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 27240 entries, 0 to 27239\n",
      "Series name: age\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "27239 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 212.9 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vk_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>304375450</td>\n",
       "      <td>–ê–ª–µ–∫—Å–µ–π</td>\n",
       "      <td>–ö—É–ø—Ü–æ–≤</td>\n",
       "      <td>1.1.2007</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>664945617</td>\n",
       "      <td>‡∏ô‡∏≤‡∏á‡∏ü‡πâ‡∏≤</td>\n",
       "      <td>‡∏ò‡∏¥‡∏î‡∏≤‡∏ã‡∏≤‡∏ï‡∏≤‡∏ô</td>\n",
       "      <td>1.1.2007</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>381637103</td>\n",
       "      <td>–í–∏–∫—Ç–æ—Ä–∏—è</td>\n",
       "      <td>–†–æ–∑–Ω–∏–Ω–∞</td>\n",
       "      <td>1.1.2007</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>260892289</td>\n",
       "      <td>–í–µ—Ä–æ–Ω–∏–∫–∞</td>\n",
       "      <td>–ú–∞–ª—ã—à–µ–≤–∞</td>\n",
       "      <td>1.1.2007</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>129110414</td>\n",
       "      <td>–û–ª—å–≥–∞</td>\n",
       "      <td>–ù–∏–∫–∏—Ç–∏–Ω–∞</td>\n",
       "      <td>1.1.2007</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      vk_id first_name  last_name birth_date   age\n",
       "0   1  304375450    –ê–ª–µ–∫—Å–µ–π     –ö—É–ø—Ü–æ–≤   1.1.2007  17.0\n",
       "1   2  664945617     ‡∏ô‡∏≤‡∏á‡∏ü‡πâ‡∏≤  ‡∏ò‡∏¥‡∏î‡∏≤‡∏ã‡∏≤‡∏ï‡∏≤‡∏ô   1.1.2007  17.0\n",
       "2   3  381637103   –í–∏–∫—Ç–æ—Ä–∏—è    –†–æ–∑–Ω–∏–Ω–∞   1.1.2007  17.0\n",
       "3   4  260892289   –í–µ—Ä–æ–Ω–∏–∫–∞   –ú–∞–ª—ã—à–µ–≤–∞   1.1.2007  17.0\n",
       "4   5  129110414      –û–ª—å–≥–∞   –ù–∏–∫–∏—Ç–∏–Ω–∞   1.1.2007  17.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user = pd.read_parquet(\"user.parquet\")\n",
    "print(df_user.columns)\n",
    "\n",
    "for i in df_user.columns:\n",
    "    print(f\"Column: {i}\")\n",
    "    print(df_user[f'{i}'].info())\n",
    "\n",
    "df_user.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
